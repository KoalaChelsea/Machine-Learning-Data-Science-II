{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "#   Helper functions  #\n",
    "#######################\n",
    "# Linear activation\n",
    "def a(x,w,b):\n",
    "    a_out = x.dot(w) + b\n",
    "    return a_out\n",
    "\n",
    "# Sigmoid function\n",
    "def sigmoid(z):\n",
    "    s = 1/(1+np.exp(-z))\n",
    "    return s\n",
    "\n",
    "# Logistic unit\n",
    "def logistic(x,w,b):\n",
    "    s = sigmoid(a(x,w,b))\n",
    "    y = np.round(s)\n",
    "    return np.array([y,s]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's code up a 2-layer MLP. Our network will take in 2-dimensional input, will have a single hidden layer of 3 units, and will have a single output classification.\n",
    "\n",
    "We'll create randomized initial weights for our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "#Setting up dimensions of 2 Layer NN\n",
    "\n",
    "n_dims = 2\n",
    "n_hidden_units = 3\n",
    "\n",
    "# Settng up the weight parameters for Layer 1\n",
    "w_11, w_12, w_13, w_21, w_22, w_23 = np.random.random(n_dims * n_hidden_units)\n",
    "\n",
    "# Setting up weight parameters for Layer 2\n",
    "v_1,v_2,v_3 = np.random.random(n_hidden_units)\n",
    "\n",
    "# Random intializiation of the biases\n",
    "# Layer 1\n",
    "b_11,b_12,b_13 = np.random.random(n_hidden_units)\n",
    "b_1 = np.array([b_11,b_12,b_13])\n",
    "# Layer 2\n",
    "b_2 = np.random.random(1)\n",
    "\n",
    "# Restructing for ease of implementation\n",
    "w_1 = np.array([w_11,w_12,w_13])\n",
    "w_2 = np.array([w_21,w_22, w_23])\n",
    "#w_3 = np.array([w_31,w_32])\n",
    "\n",
    "w = np.array([w_1,w_2])\n",
    "v = np.array([v_1,v_2,v_3])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.56664321, 0.31239171, 0.05844807],\n",
       "       [0.55496316, 0.68733418, 0.41071496]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedforward_network_v1(x, w, v, b_1, b_2):\n",
    "    '''\n",
    "    A simple 2 layer neural network with sigmoid activation and binary output.\n",
    "    '''\n",
    "    # Setting up our output y\n",
    "    num_rows,num_columns = x.shape\n",
    "    y = np.zeros((num_rows))\n",
    "    \n",
    "    for i in range(num_rows):\n",
    "        x_i = x[i,:]\n",
    "        \n",
    "        # Linear activations into hidden units\n",
    "        a1 = x_i[0]*w[0,0] + x_i[1]*w[1,0] + b_1[0]\n",
    "        a2 = x_i[0]*w[0,1] + x_i[1]*w[1,1] + b_1[1]\n",
    "        a3 = x_i[0]*w[0,2] + x_i[1]*w[1,2] + b_1[2]\n",
    "        \n",
    "        # output of hidden units\n",
    "        h_1 = sigmoid(a1)\n",
    "        h_2 = sigmoid(a2)\n",
    "        h_3 = sigmoid(a3)\n",
    "        h = np.array([h_1,h_2,h_3])\n",
    "        \n",
    "        # Output of network\n",
    "        y[i] = sigmoid(h_1*v[0] + h_2*v[1] + h_3*v[2] + b_2)\n",
    "    \n",
    "    return np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here's some randomized input data\n",
    "num_samples=50\n",
    "x = np.random.uniform(low=(-5.0), high=5.0, size=2*num_samples).reshape(num_samples,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.68352553, 0.82156177, 0.68512172, 0.69369288, 0.86404433])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feedforward_network_v1(x[:5,:], w, v, b_1, b_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that all of this arithmetic was done explicity by indexing into our weight matrixes and vectors. But we know we can accomplish the same thing with vector arithmetic. For the linear activations into a hidden unit, this weighted sum is the same as a dot product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedforward_network_v2(x, w, v, b_1, b_2):\n",
    "    '''\n",
    "    A simple 2 layer neural network with sigmoid activation and binary output.\n",
    "    '''\n",
    "    # Setting up our output y\n",
    "    l,_ = x.shape\n",
    "    y = np.zeros((l))\n",
    "    \n",
    "    for i in range(l):\n",
    "        x_i = x[i,:]\n",
    "        # Setting up the hidden units\n",
    "        h_1 = sigmoid(a(x[i,:],w[:,0],b_1[0]))\n",
    "        h_2 = sigmoid(a(x[i,:],w[:,1],b_1[1]))\n",
    "        h_3 = sigmoid(a(x[i,:],w[:,2],b_1[2]))\n",
    "        h = np.array([h_1,h_2,h_3])\n",
    "        # Calculating the output\n",
    "        y[i] = sigmoid(a(h,v,b_2))\n",
    "    \n",
    "    return np.array(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.68352553, 0.82156177, 0.68512172, 0.69369288, 0.86404433])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feedforward_network_v2(x[:5,:], w, v, b_1, b_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, note that we're using a for-loop to compute the forward pass for each input X. This can also be vectorized instead of using a loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedforward_network_v3(x, w, v, b_1, b_2):\n",
    "    '''\n",
    "    A simple 2 layer neural network with sigmoid activation and binary output.\n",
    "    '''\n",
    "    \n",
    "    a = np.dot(x,w) + b_1\n",
    "    h = sigmoid(a)\n",
    "    y = sigmoid(np.dot(h,v) + b_2)\n",
    "\n",
    "    return np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.68352553, 0.82156177, 0.68512172, 0.69369288, 0.86404433])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feedforward_network_v3(x[:5,:], w, v, b_1, b_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll pick a simple 1D regression example: we are representing arbitrary functions y of x. So we have a scalar input and a scalar output. Let's explore what kinds of functions our neural net is able to produce.\n",
    "\n",
    "By drawing random weights, we'll visualize a particular \"setting\" of a neural net, to see what kind of functions are possible. \n",
    "\n",
    "Depending on the number of hidden nodes, and the strength of the weights, we'll find that we can represent some pretty complex functions with a neural net. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize_weights(num_hidden_nodes, input_dim=1, wt_scale=1):\n",
    "    w = wt_scale*np.random.randn(num_hidden_nodes*input_dim).reshape((input_dim, num_hidden_nodes))\n",
    "    v = wt_scale*np.random.randn(num_hidden_nodes)\n",
    "    h_bias = wt_scale*np.random.randn(num_hidden_nodes)\n",
    "    y_bias = wt_scale*np.random.randn(1) \n",
    "    return (w, v, h_bias, y_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=np.expand_dims(np.linspace(-20,20,250), 1)\n",
    "z = randomize_weights(3,wt_scale=1)\n",
    "y_pred = feedforward_network_v3(x, *z)\n",
    "plt.plot(x, y_pred)\n",
    "plt.ylim((0,1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
